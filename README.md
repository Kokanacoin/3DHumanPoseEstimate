# 3DHumanPoseEstimate

基于自编码与CNN实现对2D人物照片预测3D人体姿势。

参考论文，在其复现的基础上稍加改进。

> Tekin, B., Katircioglu, I., Salzmann, M., Lepetit, V., & Fua, P.. Structured Prediction of 3D Human Pose with Deep Neural Networks .[C] In BMVC ,2016.

### 文件目录结构

├── AutoEncode.py

├── CNN.py

├── DataSet.py

├── DataSetForCNN.py

├── Preprocess.py

├── Visualization.py

├── main.py

├── count.npy

├── data

│  ├── Human3.6M

│  └── Preprocess

└── output

| 文件名           | 描述                                        |
| ---------------- | ------------------------------------------- |
| AutoEncode.py    | 自编码网络--人体姿势学习网络                |
| CNN.py           | 卷积神经网络--人体姿势生成网络              |
| DataSet.py       | 自编码网络数据导入                          |
| DataSetForCNN.py | CNN网络数据导入                             |
| Preprocess.py    | 数据预处理                                  |
| Visualization.py | 数据可视化 包括2D图片人体检出，三维空间建模 |
| main.py          | main                                        |

数据集下载：链接: https://pan.baidu.com/s/1uc9ABoy-vYo_sXyshccYVw  密码: qibj

## 数据集的预处理

采用开源数据集Human3.6M作为训练数据集，已经获得下载权限并下载成功。Human3.6M分为11名演员，考虑到数据集的大小，下载了7名演员的图片数据集，其中6名演员图片集作为训练集，1名演员图片集作为测试集使用。

人在数据集当中，用17个关键性人体关节位置代表人体的姿势。每一个关节都会在3D空间中具有x、y、z三个属性，每名演员的每一个动作中的每一帧的3D人体姿势姿势都会对应着一个这样的17*3的3D人体关节空间坐标，用来训练使用。每个关节都具有关联性，在下一节AutoEncoder网络会具体说明如何学习这样的关联性。

数据集中人物在图片里显示过小，也就是图片中人物的四周有着很多空白、背景等干扰因素，Human3.6M还提供给我们关于四个摄像机的焦距、旋转矩阵、偏移量等参数，可以通过上面人体3D中的坐标来确定人物在2D照片中的位置，进而可以缩小图片范围，以人物为中心的图片不仅仅占地小，更易于训练CNN网络。

由于3D的空间坐标存在相对性，不同摄像机的角度会得到不同的拍摄照片从而会影响神经网络的预测。4个照相机的照片虽然不同，但是数据集中给出的人物身上得到的传感器的关节空间位置却是相同。通过Human3.6M数据集给出的人体三维空间的位置矩阵乘以旋转矩阵，在加上平移向量就可以得到人物在当前摄像机中所在的三维空间坐标。这样一来，人物的三维坐标从世界坐标系就转变成相机坐标系。接下将刚刚得到的基于相机坐标系的人物坐标利用图3-3中的小孔成像原理转换为照片像素坐标系的坐标，由此可以将3D模型转换为2D模型。

![](http://qvx85o9hv.hn-bkt.clouddn.com/paper16.png)

## 姿势学习网络

![](http://qvx85o9hv.hn-bkt.clouddn.com/paper10.png)

本文使用一种自编码技术去将一个加入了高斯噪声污染的低维度的人体姿势He映射到高维度的HL上，进而学习各个关节之间潜在的关系。在这个自编码网络里，可以有多层隐藏层。

## 姿势生成网络

![](http://qvx85o9hv.hn-bkt.clouddn.com/paper13.png)

这是人物姿势生成卷积神经网络的大致结构，其中输入图片的大小的像素为112*112，由于数据集中的摄像机为RGB摄像机，因此有三个通道，深度为3。C1、C2、C3都是卷积层，每一个卷积层都会将图片压缩，使其深度加深，为了保证图片的完整性，本文选择最大卷积，一些参数细节会在后面的实验细节里面说明。每一个卷积层后后都会紧跟着一个最大池化层，以提取卷积后图片中最重要的细节。在图像卷积部分之后，为了防止训练的时候梯度下降过慢，避免偶尔会发生的梯度弥散的问题的出现，C3卷积层池化的后面加入了一个BN批量归一化层，由于训练量过大，需要分批次导入数据，如果每层的数据分布都不一样的话，将会导致网络非常难收敛和训练，而如果把每层的数据都在转换在均值为零，方差为1 的状态下，这样每层数据的分布都是一样的训练会比较容易收敛。在训练姿势生成网络的时候，minibatch中的所有的数据样本都被BN关联起来，因此网络综合这组样本而不是单单考虑一个计算，也就是说单独的一条数据要依附于这组数据。而在导入数据的时候具有随机性，每次导入的batch也是随机的，这样就可以让网络分散的学习。一定程度上避免了过拟合。通过BN层的数据流入了后面D1、D2、D3的中间层，每层的神经元数量分别是512、2048、4096。为了避免过拟合，这些中间隐藏层都是使用ReLU的激励函数。因为卷积神经网络非常容易出现过拟合的状况，在后面的隐藏层D1、D2、D3的每一层之后加入概率为0.5的dropout层，当网络开始训练的时候dropout就可以发挥作用，正常情况下每层的神经元都会参与运算，dropout有一定概率可以随机的冻结忽略一层当中的一些参数，使用这种符合随机丢弃的梯度下降，可以使得在不同的网络里面训练mini-batch，因此dropout可以非常显著的防止过拟合的发生。最后的输出层需要人体空间姿势可能在坐标内存在负数，因此在输出层选用linear作为激励函数。

## 微调

![](http://qvx85o9hv.hn-bkt.clouddn.com/paper12.png)

网络大致分为鉴别网络于生成网络两种，自编码网络就如鉴别网络，这种自编码技术可以学习人体关节之间的潜在关系，CNN卷积神经网路就如生成网络，用来从2D单眼人物图片生成3D空间姿势。当学习人体潜在姿势的自编码网络于用来生成人体空间姿势的卷积神经网络全部训练完成并且已经使得网络收敛时，这些神经网络中每一层都权重需要保留下来。通过这些学习过权重，在最后进行一次迁移微调，从而达到最好的效果。

## 结果

![](http://qvx85o9hv.hn-bkt.clouddn.com/paper14.png)